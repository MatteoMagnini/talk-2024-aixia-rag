% !TeX spellcheck = en_GB
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[handout]{beamer}\mode<handout>{\usetheme{default}}
%
%\documentclass[presentation]{beamer}\mode<presentation>{\usetheme{blackAMSBolognaFC}}
\documentclass[handout]{beamer}\mode<handout>{\usetheme{AMSBolognaFC}}
% \setbeamertemplate{bibliography item}{\insertbiblabel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[labelformat=empty]{caption}
\usepackage{listings}
\usepackage{tabularx}
\usepackage{subcaption}
\usepackage[most]{tcolorbox}
%
\usepackage{talk-2024-aixia-rag}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[RAG on LLMs for Medical Chatbot]{%
    % same title of the presented paper
    \small{
        \large{
            Applying Retrieval-Augmented Generation on Open LLMs
            \\
            for a Medical Chatbot Supporting Hypertensive Patients
        }
    }
}
%
% \subtitle{Extended Abstract}
%
% same authors order of the presented paper
\author[Aguzzi et al.]{
	Gianluca Aguzzi$^{*}$ % empth the presenting author
	\and 
	Matteo Magnini$^{*}$
	\and
	Giuseppe Pio Salcuni$^{*}$
	\\
	Stefano Ferretti$^{*}$
    \and
    \emph{Sara Montagna$^{\dagger}$}
}
%
\institute[UniBo, UniUrb]{
    $^{*}$Department of Computer Science and Engineering (DISI)
    \\
    \textsc{Alma Mater Studiorum} -- University of Bologna
    \\
    \texttt{
        \{gianluca.aguzzi, matteo.magnini, stefano.ferretti\}@unibo.it
    }
    \\
    \texttt{
        giuseppepio.salcuni@studio.unibo.it
    }
    \vspace{.3cm}
    \\
    $^{\dagger}$Department of Pure and Applied Sciences (DiSPeA)
    \\
    University of Urbino
    \\
    \texttt{\emph{sara.montagna}@uniurb.it}
}
%
\date[HC@AIxIA, 2024]{
    \small{
        \small{
            3rd AIxIA Workshop on Artificial Intelligence For Healthcare (HC@AIxIA)
            \\
            27-28 November 2024, Bolzano, Italy
        }
    }
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\AtBeginSection[]
{
%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}<beamer>[c,noframenumbering]
\frametitle{Next in Line\ldots}
\tableofcontents[sectionstyle=show/shaded,subsectionstyle=hide]
\end{frame}
%\\\\\\\\\\\\\\\\\\\\\
}
\AtBeginSubsection[]
{
%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}<beamer>[shrink,noframenumbering]
    \frametitle{Focus on\ldots}
	\mbox{~}
	\tableofcontents[currentsubsection,sectionstyle=shaded,subsectionstyle=show/shaded]
	\mbox{~}
\end{frame}
%\\\\\\\\\\\\\\\\\\\\\
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\\\\\\\\\\\\\\\\\\\\\
\frame{\titlepage}
%\\\\\\\\\\\\\\\\\\\\\

%===============================================================================
\section{Motivation \& Context}
%===============================================================================

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[c]{Context}
    
    Chronic Disease Management Challenges
    %
    \vfill
    %
    \begin{itemize}
        %
        \item Managing chronic diseases is \alert{costly} and \alert{time-intensive}
        %
    \end{itemize}
    \vfill
    \centering
    \includegraphics[width=.6\textwidth]{figures/public-health-expenditure-share-gdp}
    \vfill

\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[c]{Motivation}
    Why a Medical Chatbot for Hypertension?
    %
    \vfill
    %
    \begin{itemize}
        %
        \item Hypertension management requires ongoing support
        %
        \begin{itemize}
            \item \alert{monitoring}
            %
            \item \alert{guidance}
            %
            \item education
        \end{itemize}
        %
        \item Reduce healthcare barriers while maintaining \alert{accuracy} and \alert{privacy}
        %
        \item Open-source \alert{Large Language Models (LLMs)} overcome privacy concerns but need enhanced accuracy and domain-specific knowledge
        \begin{itemize}
            \item[$\rightarrow$] quest for diminishing \alert{hallucinations}!
        \end{itemize}
        %
    \end{itemize}
    \vfill
\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}{Contribution}

    \begin{block}{Main contributions of our work}
        \begin{itemize}
            %
            \item Improved our chatbot for hypertensive patients using \alert{open LLMs}
            %
            \item Incorporated \alert{Retrieval-Augmented Generation (RAG)} for enhanced performance
            %
            \item \alert{Evaluated} several open-source LLMs with and without RAG
        \end{itemize}
    \end{block}
    \vfill
    \begin{figure}
        \begin{minipage}{0.3\textwidth}
            \centering
            \includegraphics[width=0.6\textwidth]{figures/telegram-bot}
            \caption{Try me!}
        \end{minipage}
        \hspace{0.2cm}
        \begin{minipage}{0.3\textwidth}
            \centering
            \includegraphics[width=0.6\textwidth]{figures/github-repo}
            \caption{Check the code!}
        \end{minipage}
        \hfill
        \label{fig:telegram-bot}
    \end{figure}


\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%===============================================================================
\section{Theory, Experiments \& Results}
%===============================================================================

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[allowframebreaks]
\frametitle{Theory}
    %
    \begin{block}{The RAG system}
        \vfill
        %
        \begin{itemize}
            %
            \item Key components
            %
            \begin{itemize}
                \item \alert{Retriever} $\rightarrow$ finds relevant information
                %
                \item \alert{Generator} $\rightarrow$ generates responses based on retrieved information
                %
            \end{itemize}
            %
        \end{itemize}
    \end{block}
    \vfill
    \centering
    \includegraphics[width=.6\textwidth]{figures/rag-architecture}
    \vfill

    \framebreak

    \begin{block}{The RAG system}
        \begin{itemize}
            \item Data source $\rightarrow$ a collection of documents stored in a vector space
            \begin{itemize}
                \item[$\rightarrow$] in our case a collection of questions and answers verified by real doctors
            \end{itemize}
            %
            \item Different retrieval strategies
            %
            \begin{itemize}
                \item Base $\rightarrow$ vector similarity with the query
                %
                \item Ensemble $\rightarrow$ multiple retrievers
                %
                \item MultiQuery $\rightarrow$ multiple queries
            \end{itemize}
        \end{itemize}
    \end{block}
    %
    \begin{block}{Why RAG and not finetuning?}
        \begin{itemize}
            \item Improve our previous work on the hypertension chatbot~\ccite{telmed2024}
            \begin{itemize}
                \item[$\rightarrow$] multiple users, need to \alert{adapt} to different contexts
            \end{itemize}
            %
            \item Fine-tuning LLMs is expensive and time-consuming
            %
            \item Avoid model \alert{drift}, \alert{hallucinations}, and other issues
        \end{itemize}
    \end{block}
\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[allowframebreaks]
\frametitle{Experiments}

    \begin{block}{Experimental setup}
        \begin{itemize}
            \item Datasets $\rightarrow$ \alert{1,473} question-answer pairs extracted from medical consultations
            \begin{itemize}
                \item[$\rightarrow$] questions cover a wide range of topics related to hypertension, including \alert{symptoms}, \alert{causes}, \alert{treatments}, and \alert{lifestyle recommendations}
            \end{itemize}
            %
            \item Models $\rightarrow$ both of general-purpose models and medical-domain-specific models
            %
            \item Metrics $\rightarrow$ We used three metrics to evaluate the performance of the models:
            \begin{itemize}
                \item[$\rightarrow$] Answer relevancy $\rightarrow$ assessing the \alert{relevance} of the answer to the question
                \item[$\rightarrow$] Answer correctness $\rightarrow$ evaluating the \alert{correctness} of the answer
                \item[$\rightarrow$] Faithfulness $\rightarrow$ measuring the \alert{alignment} between the answer and the retrieved information
            \end{itemize}
            %
        \end{itemize}
    \end{block}

    \framebreak

    \vfill
    \tiny{
        \footnotesize{
            \begin{table}[htbp]
                \centering
                %\caption{Evaluated LLMs for our study.}
                \label{tab:evaluated-llms}
                \begin{tabular}{|l|p{0.6\textwidth}|}
                    \hline
                    \textbf{Model} & \textbf{Description} \\
                    \hline
                    Llama3.1 & A general-purpose LLM based on the Llama3 architecture with 8B parameters, trained on a diverse range of text data~\ccite{llama3}. \\
                    \hline
                    Llama3.1-Medical & A medical-domain-specific version of Llama3.1, fine-tuned on medical data to enhance its performance in healthcare. \\
                    \hline
                    Qwen2 & A 7B parameters general-purpose LLM, trained on 29 languages to improve cross-lingual performance~\ccite{qwen2}. \\
                    \hline
                    Qwen2-Medical & A medical-domain-specific version of Qwen2, fine-tuned on medical data to improve its performance in healthcare tasks. \\
                    \hline
                    Mistral-Nemo & A 12B parameter model with a large context window (128K tokens) developed by Nvidia. \\
                    \hline
                    Phi3 & A small LLM with 3B parameters, trained by Microsoft on filtered high-quality data~\ccite{abdin2024phi3technicalreporthighly}. \\
                    \hline
                    Gemma2 & A 9B parameter model based on Deepmind Gemini developed by Google~\ccite{gemmateam2024gemma2improvingopen}. \\
                    \hline
                \end{tabular}
            \end{table}
        }
    }
    \vfill

\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[allowframebreaks]
    \frametitle{Results}



\end{frame}

%===============================================================================
\section{Case study / Experiments / Results}

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}%[allowframebreaks]
\frametitle{Case study / Experiments / Results}

    Provide 2-3 slides discussing the Case study / Experiments / Results of the paper

\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

\section{Conclusions \& future works}

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}%[allowframebreaks]
\frametitle{Conclusions \& future works}

\begin{block}{Summing up}
    Summarise the most relevant contributions of this study:
    %
    \begin{itemize}
        \item conclusion 1
        \item conclusion 2
        \item conclusion 3
    \end{itemize}
\end{block}

\begin{exampleblock}{Future works}
    Sketch some future research directions
    %
    \begin{itemize}
        \item future work 1
        \item future work 2
    \end{itemize}
\end{exampleblock}

(may be split into 2 slides)

\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%===============================================================================
\section*{}
%===============================================================================
\frame{\titlepage}

%===============================================================================
\section*{\bibname}
%===============================================================================

\setbeamertemplate{page number in head/foot}{}
%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[t,allowframebreaks,noframenumbering]\frametitle{\refname}
% \begin{frame}[c]\frametitle{\refname}
	\footnotesize
%	\scriptsize
    \bibliographystyle{apalike-AMS}
    % \bibliographystyle{plain}
	\bibliography{talk-2024-aixia-rag}
\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
